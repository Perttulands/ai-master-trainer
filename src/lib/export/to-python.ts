/**
 * Generated by Training Camp
 * Python/LangChain Export Module
 *
 * Generates LangChain-compatible Python code from an AgentDefinition.
 * The generated code uses ChatOpenAI and AgentExecutor for agent execution.
 */

import type { AgentDefinition, AgentTool } from '../../types/agent';

/**
 * Escapes a string for use in Python triple-quoted strings.
 */
function escapePythonString(str: string): string {
  return str
    .replace(/\\/g, '\\\\')
    .replace(/"""/g, '\\"\\"\\"')
    .replace(/'''/g, "\\'\\'\\'");
}

/**
 * Converts a JavaScript/TypeScript type to a Python type hint.
 */
function toPythonType(jsType: string): string {
  const typeMap: Record<string, string> = {
    string: 'str',
    number: 'float',
    integer: 'int',
    boolean: 'bool',
    object: 'dict',
    array: 'list',
  };
  return typeMap[jsType.toLowerCase()] || 'Any';
}

/**
 * Generates Python code for a single tool function.
 */
function generateToolFunction(tool: AgentTool): string {
  const params = tool.parameters
    .map((p) => {
      const pyType = toPythonType(p.type);
      return p.required ? `${p.name}: ${pyType}` : `${p.name}: ${pyType} = None`;
    })
    .join(', ');

  const paramDocs = tool.parameters
    .map((p) => `        ${p.name}: ${p.description}`)
    .join('\n');

  return `
@tool
def ${tool.name}(${params}) -> str:
    """${tool.description}

    Args:
${paramDocs}

    Returns:
        str: The result of the tool execution.
    """
    # TODO: Implement tool logic
    raise NotImplementedError("Tool '${tool.name}' needs implementation")
`;
}

/**
 * Exports an AgentDefinition to LangChain-compatible Python code.
 *
 * @param agent - The agent definition to export
 * @returns A string containing the generated Python code
 */
export function exportToPython(agent: AgentDefinition): string {
  const toolFunctions = agent.tools.map(generateToolFunction).join('\n');
  const toolNames = agent.tools.map((t) => t.name).join(', ');

  const modelName =
    agent.parameters.model.includes('gpt') ||
    agent.parameters.model.includes('openai')
      ? agent.parameters.model
      : 'gpt-4';

  return `#!/usr/bin/env python3
"""
Generated by Training Camp
Agent: ${agent.name}
Version: ${agent.version}
Description: ${agent.description}

This file contains a LangChain-compatible agent implementation.
"""

from typing import Any, Optional
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool


# =============================================================================
# System Prompt
# =============================================================================

SYSTEM_PROMPT = """${escapePythonString(agent.systemPrompt)}"""


# =============================================================================
# Tool Definitions
# =============================================================================
${toolFunctions}

# =============================================================================
# Agent Creation
# =============================================================================

def create_agent(
    model_name: str = "${modelName}",
    temperature: float = ${agent.parameters.temperature},
    max_tokens: int = ${agent.parameters.maxTokens},
    verbose: bool = False,
) -> AgentExecutor:
    """
    Creates and returns the configured agent executor.

    Args:
        model_name: The OpenAI model to use.
        temperature: Sampling temperature (0.0 to 1.0).
        max_tokens: Maximum tokens in the response.
        verbose: Whether to print verbose output.

    Returns:
        AgentExecutor: The configured agent executor.
    """
    # Initialize the language model
    llm = ChatOpenAI(
        model=model_name,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    # Define available tools
    tools = [${toolNames}]

    # Create the prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # Create the agent
    agent = create_openai_functions_agent(llm, tools, prompt)

    # Create and return the executor
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=verbose,
        handle_parsing_errors=True,
    )


# =============================================================================
# Main Entry Point
# =============================================================================

if __name__ == "__main__":
    import asyncio

    async def main():
        """Run the agent in interactive mode."""
        print("=" * 60)
        print(f"${agent.name} v${agent.version}")
        print("=" * 60)
        print("${agent.description}")
        print("-" * 60)
        print("Type 'quit' or 'exit' to stop.")
        print()

        agent_executor = create_agent(verbose=True)
        chat_history = []

        while True:
            try:
                user_input = input("You: ").strip()

                if user_input.lower() in ("quit", "exit"):
                    print("Goodbye!")
                    break

                if not user_input:
                    continue

                result = await agent_executor.ainvoke({
                    "input": user_input,
                    "chat_history": chat_history,
                })

                print(f"\\nAgent: {result['output']}\\n")

                # Update chat history
                chat_history.extend([
                    ("human", user_input),
                    ("ai", result["output"]),
                ])

            except KeyboardInterrupt:
                print("\\nGoodbye!")
                break
            except Exception as e:
                print(f"\\nError: {e}\\n")

    asyncio.run(main())
`;
}
